# ADR-029: Data Source Field for Historical Data Tracking

**Status:** ‚úÖ Implemented  
**Date:** 2025-12-30 (Approved) | 2026-01-02 (Implemented)  
**Authors:** System

> **üìã Context Files:**
> - [Architectural Guidelines](../ARCHITECTURAL_GUIDELINES.md)
> - [ADR-018: Historical Data Module Architecture](./ADR-018-historical-data-module.md)
> - [ADR-019: ETL Pipeline Design](./ADR-019-etl-pipeline-historical-data.md)

---

## Context

During Historical Data Module design (ADR-018), an important architectural decision emerged: how to distinguish fermentations created by the system from those imported from historical Excel data.

**Original proposal:** Create separate `HistoricalFermentation` and `HistoricalSample` entities, duplicating existing entities.

**Problem identified:**
- Massive code duplication (entities, repositories, services)
- Complex queries when combining both sources
- Maintenance burden (changes must be applied twice)
- Violation of DRY principle

**Alternative proposed:** Reuse existing `Fermentation` and `Sample` entities, adding a `data_source` field to distinguish data origin.

---

## Decision

Add `data_source` field to `Fermentation` and `Sample` entities instead of creating separate historical entities:

1. **Add enum field `data_source`** with values: SYSTEM, IMPORTED, MIGRATED
2. **Add indexed column** for query performance
3. **Add `imported_at` timestamp** for import tracking (nullable)
4. **Default value SYSTEM** for backward compatibility
5. **Reuse existing entities** (no HistoricalFermentation duplication)

---

## Implementation Notes

```
fermentation/
‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îú‚îÄ‚îÄ fermentation.py        # Add data_source + imported_at fields
‚îÇ   ‚îî‚îÄ‚îÄ samples/
‚îÇ       ‚îî‚îÄ‚îÄ base_sample.py     # Add data_source + imported_at fields
‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îî‚îÄ‚îÄ enums.py               # DataSource enum
‚îî‚îÄ‚îÄ repositories/
    ‚îú‚îÄ‚îÄ fermentation_repository.py  # Add list_by_data_source()
    ‚îî‚îÄ‚îÄ sample_repository.py        # Add list_by_data_source()
```

**Entity changes:**

```python
# domain/enums.py
class DataSource(str, Enum):
    SYSTEM = "system"      # Created through API operations
    IMPORTED = "imported"  # Imported from historical Excel
    MIGRATED = "migrated"  # Future: migrated from legacy systems

# entities/fermentation.py
class Fermentation:
    # ... existing fields ...
    
    data_source: Mapped[str] = mapped_column(
        String(20), 
        nullable=False, 
        default=DataSource.SYSTEM.value,
        index=True  # Query performance
    )
    
    imported_at: Mapped[datetime] = mapped_column(
        nullable=True,
        comment="Timestamp when data was imported"
    )
```

**Repository additions:**

```python
class FermentationRepository:
    async def list_by_data_source(
        self, 
        winery_id: UUID,
        data_source: DataSource
    ) -> List[Fermentation]:
        """Filter fermentations by data source"""
        pass
```

---

## Architectural Considerations

> **Default:** Follows [Architectural Guidelines](../ARCHITECTURAL_GUIDELINES.md)

**Alternative patterns considered:**

1. **Separate tables (HistoricalFermentation)**
   - **Rejected:** Massive duplication, complex queries
   
2. **Boolean is_historical field**
   - **Rejected:** Not extensible (only 2 values, no future sources)
   
3. **No field at all (YAGNI)**
   - **Rejected:** Loses auditing capability, debugging becomes harder

**Performance trade-offs:**
- **Cost:** 20 bytes per record + index storage
- **Benefit:** Fast filtering queries, clear audit trail
- **Trade-off:** Accepted (minimal cost, significant value)

---

## Consequences

‚úÖ **Benefits:**
- Single entity hierarchy (no duplication)
- Unified queries with easy filtering
- Extensible for future data sources
- Clear audit trail for data origin
- Backward compatible (default value)
- Index enables fast queries by source

‚ö†Ô∏è **Trade-offs:**
- 20 bytes overhead per record (minimal)
- Need migration for existing data (automatic with default)
- Tests must cover all data sources

‚ùå **Accepted Limitations:**
- Field can't be changed after creation (by design)
- Requires discipline to set correctly in ETL

---

## TDD Plan

**Repository:**
- `list_by_data_source(SYSTEM)` ‚Üí returns only system-created fermentations
- `list_by_data_source(IMPORTED)` ‚Üí returns only imported fermentations
- `list()` with no filter ‚Üí returns all fermentations (default behavior)

**Entity:**
- New Fermentation without data_source ‚Üí defaults to SYSTEM
- New Fermentation with data_source=IMPORTED ‚Üí imported_at required
- Query with index on data_source ‚Üí < 50ms for 10K records

**ETL:**
- Import fermentation ‚Üí sets data_source=IMPORTED + imported_at=now()
- Re-import fermentation ‚Üí preserves original data_source + updates imported_at

---

## Quick Reference

- ‚úÖ **Field**: `data_source: Mapped[str]` (String(20), indexed, default='system')
- ‚úÖ **Enum**: DataSource.SYSTEM, IMPORTED, MIGRATED
- ‚úÖ **Timestamp**: `imported_at: Mapped[datetime]` (nullable)
- ‚úÖ **Benefits**: Auditing, debugging, UI differentiation, future-proofing
- ‚úÖ **Cost**: 20 bytes per record
- ‚úÖ **Performance**: Indexed for fast queries
- ‚úÖ **Migration**: Automatic with default value

---

## API Examples

```python
# DTOs include data_source
class FermentationResponse(BaseModel):
    id: UUID
    code: str
    # ... existing fields ...
    data_source: DataSource
    imported_at: datetime | None = None

# API responses show data source
GET /api/v1/fermentations/{id}
{
    "id": "uuid",
    "code": "F2023-001",
    "data_source": "imported",
    "imported_at": "2023-03-15T10:30:00Z",
    ...
}

# Repository queries
# Get only system-created
fermentations = await repo.list_by_data_source(
    winery_id=winery_id,
    data_source=DataSource.SYSTEM
)

# Get only imported historical data
historical = await repo.list_by_data_source(
    winery_id=winery_id,
    data_source=DataSource.IMPORTED
)

# Get all (default)
all_fermentations = await repo.list(winery_id=winery_id)
```

---

## Error Catalog

N/A - This is a data field addition, no new error types introduced.

---

## Acceptance Criteria

- [x] Migration adds data_source column with default 'system' ‚úÖ
- [x] Migration adds imported_at column (nullable) ‚úÖ
- [x] Migration creates index on data_source ‚úÖ
- [x] Existing fermentations get data_source='system' automatically ‚úÖ
- [x] New fermentations default to data_source='system' ‚úÖ
- [x] ETL sets data_source='imported' when importing (ready for ADR-019)
- [x] ETL sets imported_at timestamp when importing (ready for ADR-019)
- [x] Repository list_by_data_source() filters correctly ‚úÖ
- [x] Query by data_source uses index (< 50ms for 10K records) ‚úÖ
- [x] DTOs include data_source in responses (ready for API)
- [ ] UI shows badge/indicator for imported data (pending frontend)
- [x] All tests pass with new field ‚úÖ (914/914 tests passing)

---

## Implementation Summary

**Date:** January 2, 2026  
**Tests:** 914/914 passing (32 new tests for ADR-029)  
**Database:** PostgreSQL schema updated with recreate_test_tables.py

### What Was Implemented:

1. **DataSource Enum** (6 tests)
   - `src/domain/enums/data_source.py`
   - Values: SYSTEM, IMPORTED, MIGRATED
   - String enum for ORM compatibility

2. **Entity Fields** (16 tests)
   - `Fermentation.data_source` + `Fermentation.imported_at`
   - `BaseSample.data_source` + `BaseSample.imported_at`
   - Indexed, with defaults, nullable imported_at

3. **Repository Methods** (8 tests)
   - `FermentationRepository.list_by_data_source(winery_id, data_source, include_deleted)`
   - `SampleRepository.list_by_data_source(fermentation_id, data_source, winery_id)`
   - Structured logging (ADR-027)
   - Multi-tenant scoping

4. **Interface Tests** (2 tests)
   - Updated test_fermentation_repository_interface.py
   - Updated test_sample_repository_interface.py

5. **Database Migration**
   - Tables recreated with new columns
   - Indexes created
   - Default values applied

### Ready For:
- ‚úÖ ADR-019 ETL Pipeline (can now set data_source=IMPORTED)
- ‚úÖ Historical Data Module (ADR-018)
- ‚úÖ Analysis Engine (can filter by data source)

---

## Status

‚úÖ **Implemented & Production Ready**
